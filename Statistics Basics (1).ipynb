{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef32667-df5e-4dac-82a0-e0078b719c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is statistics, and why is it important?\n",
    "Statistics is the study of collecting, analyzing, interpreting, presenting, and organizing data to understand patterns, trends, and relationships.\n",
    "Importance:\n",
    "Statistics is important because it helps:\n",
    "1. Make informed decisions: By analyzing data, statistics informs decision-making in various fields, such as business, healthcare, and social sciences.\n",
    "2. Understand patterns and trends: Statistics helps identify relationships and patterns in data, enabling predictions and forecasting.\n",
    "3. Evaluate evidence: Statistics provides a framework for testing hypotheses and evaluating the strength of evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e3247-b522-4ec0-a35b-52d134e313e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "What are the two main types of statistics?\n",
    "Two Main Types of Statistics:\n",
    "1. Descriptive Statistics: Summarizes and describes the basic features of data, such as mean, median, mode, and standard deviation.\n",
    "2. Inferential Statistics: Uses sample data to make conclusions or predictions about a larger population, through techniques like hypothesis testing and regression analysis.\n",
    "These two types of statistics help understand and interpret data in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8677d7-f633-41f8-bf8c-318f839494df",
   "metadata": {},
   "outputs": [],
   "source": [
    "What are descriptive statistics?\n",
    "Descriptive Statistics:\n",
    "Descriptive statistics summarize and describe the basic features of data, including:\n",
    "1. Measures of central tendency: Mean, median, mode\n",
    "2. Measures of variability: Range, variance, standard deviation\n",
    "3. Frequency distributions: Tables or graphs showing data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b1823-9a1a-4f38-ad6b-9985e9f593cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is inferential statistics?\n",
    "Inferential Statistics:\n",
    "Inferential statistics uses sample data to make conclusions or predictions about a larger population. It involves:\n",
    "1. Hypothesis testing: Testing a hypothesis about a population based on sample data.\n",
    "2. Confidence intervals: Estimating a population parameter based on sample data.\n",
    "3. Regression analysis: Modeling relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07d4ab-4ead-40ef-bb52-2c12495404b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is sampling in statistics?\n",
    "Sampling:\n",
    "Sampling is the process of selecting a subset of individuals or data from a larger population to make inferences about the whole population.\n",
    "1. Random sampling: Every member of the population has an equal chance of being selected.\n",
    "2. Stratified sampling: The population is divided into subgroups and samples are taken from each subgroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796b9e7-a521-45c7-93da-6ce2ba024284",
   "metadata": {},
   "outputs": [],
   "source": [
    "What are the different types of sampling methods?\n",
    "Types of Sampling Methods:\n",
    "1. Random Sampling: Every member has an equal chance of selection.\n",
    "2. Stratified Sampling: Population is divided into subgroups and samples are taken from each.\n",
    "3. Systematic Sampling: Samples are selected at regular intervals.\n",
    "4. Cluster Sampling: Population is divided into clusters and random samples are taken.\n",
    "5. Convenience Sampling: Samples are selected based on ease of access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512acbd-013e-41e0-b562-0e59f0c4bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the difference between random and non-random sampling?\n",
    "Random vs Non-Random Sampling:\n",
    "Random Sampling:\n",
    "- Every member of the population has an equal chance of being selected.\n",
    "- Reduces bias and increases representativeness.\n",
    "Non-Random Sampling:\n",
    "- Selection is based on factors other than random chance (e.g., convenience, quota).\n",
    "- May introduce bias and reduce representativeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5f927-10f8-4b84-9025-92c0f8938465",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define and give examples of qualitative and quantitative data?\n",
    "Qualitative Data:\n",
    "- Non-numerical data that describes characteristics or attributes.\n",
    "- Examples:\n",
    "    - Colors (red, blue, green)\n",
    "    - Textures (soft, rough, smooth)\n",
    "    - Opinions (good, bad, excellent)\n",
    "Quantitative Data:\n",
    "- Numerical data that can be measured or counted.\n",
    "- Examples:\n",
    "    - Height (175 cm)\n",
    "    - Weight (65 kg)\n",
    "    - Age (25 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96507864-6e8e-44ea-87f2-426f4c940570",
   "metadata": {},
   "outputs": [],
   "source": [
    "What are the different types of data in statistics?\n",
    "Types of Data:\n",
    "1. Nominal Data: Categorical data with no inherent order (e.g., colors, names).\n",
    "2. Ordinal Data: Categorical data with a natural order (e.g., rankings, ratings).\n",
    "3. Interval Data: Numerical data with equal intervals between values (e.g., temperature).\n",
    "4. Ratio Data: Numerical data with a true zero point (e.g., weight, height)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05140943-fe23-4f5e-97e8-a6ec0274c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "Explain nominal, ordinal, interval, and ratio levels of measurement?\n",
    "Levels of Measurement:\n",
    "1. Nominal: Categorical data, no order or ranking (e.g., colors, names).\n",
    "2. Ordinal: Categorical data with a natural order or ranking (e.g., ratings, rankings).\n",
    "3. Interval: Numerical data with equal intervals, but no true zero point (e.g., temperature in Celsius).\n",
    "4. Ratio: Numerical data with a true zero point and equal intervals (e.g., weight, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7009f2e-ca6c-4ece-a3e7-1e2527eb9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the measure of central tendency?\n",
    "Measure of Central Tendency:\n",
    "A measure of central tendency is a statistical measure that identifies a single value as representative of an entire dataset. The three main types are:\n",
    "1. Mean: Average value\n",
    "2. Median: Middle value\n",
    "3. Mode: Most frequently occurring value\n",
    "These measures help summarize and describe the central position of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc4e1a-87b6-4b95-8efe-ab15f0343646",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define mean, median, and mode?\n",
    "Mean, Median, and Mode:\n",
    "1. Mean: The average value of a dataset, calculated by summing all values and dividing by the number of values.\n",
    "2. Median: The middle value of a dataset when it is ordered from smallest to largest. If there are an even number of values, the median is the average of the two middle values.\n",
    "3. Mode: The value that appears most frequently in a dataset. A dataset may have one mode, multiple modes, or no mode at all.\n",
    "These measures help describe the central tendency of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e157c-e5be-4fde-9136-153db2c1e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the significance of the measure of central tendency?\n",
    "Significance of Measure of Central Tendency:\n",
    "Measures of central tendency (mean, median, mode) are significant because they:\n",
    "1. Summarize data: Provide a single value that represents the entire dataset.\n",
    "2. Compare datasets: Enable comparison of different datasets or groups.\n",
    "3. Inform decisions: Help make informed decisions by providing a snapshot of the data.\n",
    "These measures provide insights into the characteristics of a dataset and facilitate data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f6cd8-96cd-49bc-b801-bb7b495243ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is variance, and how is it calculated?\n",
    "Variance:\n",
    "Variance measures the spread or dispersion of data from the mean value. It calculates the average of the squared differences between \n",
    "each data point and the mean.\n",
    "Calculation:\n",
    "1. Calculate the mean of the dataset.\n",
    "2. Subtract the mean from each data point to find the deviation.\n",
    "3. Square each deviation.\n",
    "4. Calculate the average of the squared deviations.\n",
    "Variance helps understand the variability and spread of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd32c0e-9101-4b5b-b06f-d88b956c549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is standard deviation, and why is it important?\n",
    "Standard Deviation:\n",
    "Standard deviation is a measure of the amount of variation or dispersion of a set of values. It represents how spread out the data is from the mean.\n",
    "Importance:\n",
    "Standard deviation is important because it:\n",
    "1. Measures risk: Helps assess uncertainty or risk in investments, predictions, or decisions.\n",
    "2. Compares datasets: Enables comparison of variability between different datasets or groups.\n",
    "3. Identifies outliers: Helps detect data points that are significantly different from the mean.\n",
    "Standard deviation provides insights into data distribution and is a key concept in statistics and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b37851-32bb-4f69-bf25-f31609583ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define and explain the term range in statistics?\n",
    "Range is the difference between the largest and smallest values in a dataset. It's calculated by subtracting the minimum value from the maximum value.\n",
    "Dataset: 2, 5, 8, 12, 15\n",
    "Range = Maximum value (15) - Minimum value (2) = 13\n",
    "Range provides a simple measure of data spread or dispersion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7243a5-ac65-4d3f-b6bc-b3bf91415b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the difference between variance and standard deviation?\n",
    "Variance vs Standard Deviation:\n",
    "1. Variance: Measures the average of the squared differences from the mean, giving the spread of the data in squared units.\n",
    "2. Standard Deviation: The square root of variance, measuring the spread in the same units as the data.\n",
    "Both measure data dispersion, but standard deviation is more interpretable due to its unit consistency with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da2470-b76b-4b8b-ba48-1314d68a5035",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is skewness in a dataset?\n",
    "Skewness refers to the asymmetry or unevenness of a dataset's distribution. It can be:\n",
    "1. Positive skew: Tail on the right side is longer or fatter.\n",
    "2. Negative skew: Tail on the left side is longer or fatter.\n",
    "3. Zero skew: Symmetrical distribution.\n",
    "Skewness helps understand the shape and behavior of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f7d02e-80c2-4ac3-80e8-2b972d70b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "What does it mean if a dataset is positively or negatively skewed?\n",
    "Skewed Datasets:\n",
    "1. Positively Skewed: More extreme values on the right side (higher values), with a longer tail on the right.\n",
    "2. Negatively Skewed: More extreme values on the left side (lower values), with a longer tail on the left.\n",
    "Skewness affects the interpretation of mean, median, and mode, and can impact statistical analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8c281-6383-4012-920e-1e53e1a93e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define and explain kurtosis?\n",
    "Kurtosis measures the \"tailedness\" or extremity of a distribution. It describes how outlier-prone a dataset is.\n",
    "- High kurtosis: More extreme values (heavy tails)\n",
    "- Low kurtosis: Fewer extreme values (light tails)\n",
    "Kurtosis helps understand the likelihood of outliers and the distribution's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9051ab1f-29eb-473c-a4e8-a7c4e3242fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the purpose of covariance?\n",
    "Covariance:\n",
    "Covariance measures how two variables change together. It assesses the direction and strength of their linear relationship.\n",
    "- Positive covariance: Variables tend to increase or decrease together.\n",
    "- Negative covariance: One variable increases as the other decreases.\n",
    "Covariance helps understand relationships between variables and is used in portfolio management, risk analysis, and statistical modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd39b9-f36a-4fc2-a2f1-ac6835eefc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "What does correlation measure in statistics?\n",
    "Correlation:\n",
    "Correlation measures the strength and direction of the linear relationship between two variables. It ranges from -1 (perfect negative correlation) to 1 (perfect positive correlation), with 0 indicating no linear relationship.\n",
    "Correlation helps identify how closely two variables are related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c409f57-fac2-4400-b625-c766d371f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the difference between covariance and correlation?\n",
    "Covariance vs Correlation:\n",
    "1. Covariance: Measures how two variables change together, but its value depends on the units of the variables.\n",
    "2. Correlation: Standardizes covariance, measuring the strength and direction of the linear relationship between two variables on a scale from -1 to 1, regardless of units.\n",
    "Correlation is a more interpretable measure of relationship strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd5bbd-dff3-4457-88dd-d78c06041244",
   "metadata": {},
   "outputs": [],
   "source": [
    "What are some real-world applications of statistics?\n",
    "Real-World Applications of Statistics:\n",
    "1. Business: Market research, quality control, forecasting sales.\n",
    "2. Medicine: Clinical trials, disease tracking, treatment effectiveness.\n",
    "3. Finance: Risk management, portfolio optimization, investment analysis.\n",
    "4. Social Sciences: Understanding population trends, opinion polling.\n",
    "5. Sports: Player performance analysis, game strategy optimization.\n",
    "Statistics helps make informed decisions and drive insights in various fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a06b32-ee9e-4ac1-b20a-9612b3901501",
   "metadata": {},
   "outputs": [],
   "source": [
    "How do you calculate the mean, median, and mode of a dataset?\n",
    "Calculating Mean, Median, and Mode:\n",
    "1. Mean: Sum all values and divide by the number of values.\n",
    "2. Median: Arrange values in order and find the middle value (or average of two middle values if even number of values).\n",
    "3. Mode: Identify the value that appears most frequently in the dataset.\n",
    "These calculations help summarize and describe the central tendency of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db6a377-e501-4810-969f-e34248389c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a Python program to compute the variance and standard deviation of a dataset?\n",
    "I don’t understand Sundanese yet, but I’m working on it. I will send you a message when we can talk in Sundanese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c3fc9a-419a-41c6-a2d7-2991e8c9bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create a dataset and classify it into nominal, ordinal, interval, and ratio types?\n",
    "Dataset:\n",
    "| Student ID | Name | Grade | Age | Height (cm) |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 1 | John | A | 20 | 175 |\n",
    "| 2 | Emma | B | 22 | 160 |\n",
    "| 3 | David | A | 21 | 180 |\n",
    "Classification:\n",
    "1. Nominal: Name (categorical, no order)\n",
    "2. Ordinal: Grade (categorical, ordered: A, B, C, etc.)\n",
    "3. Interval: None in this dataset (e.g., temperature in Celsius)\n",
    "4. Ratio: Age, Height (numerical, with a true zero point)\n",
    "Each type of data requires different statistical analysis and visualization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65892af9-15db-48a6-b30a-59f623d68652",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implement sampling techniques like random sampling and stratified sampling?\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Category': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Value': [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "})\n",
    "# Random Sampling\n",
    "random_sample = data.sample(n=5)\n",
    "# Stratified Sampling\n",
    "stratified_sample = data.groupby('Category').apply(lambda x: x.sample(n=1)).reset_index(drop=True)\n",
    "print(\"Random Sample:\")\n",
    "print(random_sample)\n",
    "print(\"\\nStratified Sample:\")\n",
    "print(stratified_sample)\n",
    "This code demonstrates random sampling and stratified sampling using pandas and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277590f-7bc7-41d0-8f13-a072b86f9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a Python function to calculate the range of a dataset?\n",
    "Python Function:\n",
    "def calculate_range(data):\n",
    "    return max(data) - min(data)\n",
    "# Example usage:\n",
    "data = [1, 2, 3, 4, 5]\n",
    "print(\"Range:\", calculate_range(data))\n",
    "This function calculates the range of a dataset by subtracting the minimum value from the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6f9859-bd89-41e2-8ba4-0864d964fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create a dataset and plot its histogram to visualize skewness?\n",
    "Python Code:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Skewed dataset\n",
    "data = np.random.exponential(scale=1, size=1000)\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(data, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Skewed Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "This code generates a skewed dataset using exponential distribution and plots its histogram to visualize the skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e529c00-a971-4db7-af75-845a94f80ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate skewness and kurtosis of a dataset using Python libraries?\n",
    "I don’t understand Sundanese yet, but I’m working on it. I will send you a message when we can talk in Sundanese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58280d-8804-47bd-9385-d8227437bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generate a dataset and demonstrate positive and negative skewness?\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Positive Skewness (Right-Skewed)\n",
    "data_positive = np.random.exponential(scale=1, size=1000)\n",
    "\n",
    "# Negative Skewness (Left-Skewed)\n",
    "data_negative = -np.random.exponential(scale=1, size=1000)\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data_positive, bins=30, alpha=0.7, color='blue')\n",
    "plt.title('Positive Skewness')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data_negative, bins=30, alpha=0.7, color='red')\n",
    "plt.title('Negative Skewness')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "This code generates datasets with positive (right-skewed) and negative (left-skewed) skewness and plots their histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81decca4-ac14-42dc-8633-194b91ae11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a Python script to calculate covariance between two datasets?\n",
    "Python Script:\n",
    "import numpy as np\n",
    "# Sample datasets\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 3, 5, 7, 11])\n",
    "\n",
    "# Calculate covariance\n",
    "covariance = np.cov(x, y)[0, 1]\n",
    "\n",
    "print(\"Covariance:\", covariance)\n",
    "\n",
    "This script uses NumPy's cov function to calculate the covariance between two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6686a-3381-451f-ae11-4b79cadea812",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a Python script to calculate the correlation coefficient between two datasets?\n",
    "Python Script:\n",
    "\n",
    "import numpy as np\n",
    "# Sample datasets\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 3, 5, 7, 11])\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "correlation = np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "print(\"Correlation Coefficient:\", correlation)\n",
    "\n",
    "This script uses NumPy's corrcoef function to calculate the correlation coefficient between two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2d4f7-a861-471a-b68e-6be6685ad026",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create a scatter plot to visualize the relationship between two variables?\n",
    "Python Code:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample datasets\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 3, 5, 7, 11])\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Relationship between X and Y')\n",
    "plt.show()\n",
    "\n",
    "This code creates a scatter plot to visualize the relationship between two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab6575-aeac-4be6-b591-85403bf2ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implement and compare simple random sampling and systematic sampling?\n",
    "Python Code:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Population dataset\n",
    "population = pd.DataFrame({'Value': range(1, 101)})\n",
    "\n",
    "# Simple Random Sampling\n",
    "random_sample = population.sample(n=10)\n",
    "\n",
    "# Systematic Sampling\n",
    "n = 10\n",
    "k = len(population) // n\n",
    "systematic_sample = population.iloc[::k]\n",
    "\n",
    "print(\"Random Sample:\")\n",
    "print(random_sample)\n",
    "print(\"\\nSystematic Sample:\")\n",
    "print(systematic_sample)\n",
    "This code demonstrates simple random sampling and systematic sampling, highlighting their differences in selection methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69454e9d-cef4-4ace-9260-50eb86491106",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate the mean, median, and mode of grouped data?\n",
    "Python Code:\n",
    "import pandas as pd\n",
    "# Grouped data\n",
    "data = pd.DataFrame({\n",
    "    'Class': ['0-10', '10-20', '20-30', '30-40'],\n",
    "    'Frequency': [5, 10, 15, 8]\n",
    "})\n",
    "# Calculate midpoints\n",
    "data['Midpoint'] = [5, 15, 25, 35]\n",
    "# Calculate mean\n",
    "mean = (data['Midpoint'] * data['Frequency']).sum() / data['Frequency'].sum()\n",
    "# Calculate median\n",
    "data['Cumulative Frequency'] = data['Frequency'].cumsum()\n",
    "median_class = data[data['Cumulative Frequency'] >= data['Frequency'].sum() / 2].iloc[0]\n",
    "median = median_class['Midpoint']\n",
    "# Calculate mode\n",
    "mode_class = data.loc[data['Frequency'].idxmax()]\n",
    "mode = mode_class['Midpoint']\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode)\n",
    "This code calculates the mean, median, and mode of grouped data using the midpoint of each class. Note that the mode calculation assumes the modal\n",
    "class is the one with the highest frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be744415-b12e-42be-b4b3-6cded785cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Simulate data using Python and calculate its central tendency and dispersion?\n",
    "Python Code:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Simulate data\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(loc=5, scale=2, size=100)\n",
    "\n",
    "# Calculate central tendency\n",
    "mean = np.mean(data)\n",
    "median = np.median(data)\n",
    "\n",
    "# Calculate dispersion\n",
    "std_dev = np.std(data)\n",
    "variance = np.var(data)\n",
    "range_ = np.ptp(data)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Standard Deviation:\", std_dev)\n",
    "print(\"Variance:\", variance)\n",
    "print(\"Range:\", range_)\n",
    "\n",
    "This code simulates a normal distribution, calculates its central tendency (mean and median), and dispersion (standard deviation, variance, and range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a25cc3-bafe-4605-ba05-3f874653e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use NumPy or pandas to summarize a dataset’s descriptive statistics?\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'A': np.random.randint(1, 100, 10),\n",
    "    'B': np.random.randn(10)\n",
    "})\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "stats = data.describe()\n",
    "\n",
    "print(stats)\n",
    "This code uses pandas' describe function to calculate and display descriptive statistics (count, mean, std, min, 25%, 50%, 75%, max) for a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491e690-07b7-4a77-9af5-0475cda3ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot a boxplot to understand the spread and identify outliers?\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset\n",
    "data = np.random.normal(0, 1, 100)\n",
    "\n",
    "# Plot boxplot\n",
    "plt.boxplot(data, vert=False)\n",
    "plt.title('Boxplot')\n",
    "plt.show()\n",
    "\n",
    "This code creates a boxplot to visualize the spread of data and identify outliers. The box represents the interquartile range (IQR),\n",
    "and points outside 1.5*IQR are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debfe60f-2581-451e-8543-d770f395d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate the interquartile range (IQR) of a dataset?\n",
    "IQR = Q3 (75th percentile) - Q1 (25th percentile).\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "Q1 = np.percentile(data, 25)\n",
    "Q3 = np.percentile(data, 75)\n",
    "IQR = Q3 - Q1\n",
    "print(\"IQR:\", IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33739432-d2d4-4ed6-9456-65c3bdde8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implement Z-score normalization and explain its significance?\n",
    "import numpy as np\n",
    "data = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "mean = np.mean(data)\n",
    "std_dev = np.std(data)\n",
    "\n",
    "normalized_data = (data - mean) / std_dev\n",
    "\n",
    "print(\"Normalized Data:\", normalized_data)\n",
    "\n",
    "Significance: Z-score normalization (standardization) transforms data to have a mean of 0 and standard deviation of 1, allowing for:\n",
    "\n",
    "1. Comparison of datasets with different scales\n",
    "2. Improved model performance in machine learning\n",
    "3. Outlier detection and handling\n",
    "\n",
    "It helps in reducing the impact of dominant features and improves the interpretability of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548d8f0-4683-446b-9808-c250552f7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "Compare two datasets using their standard deviations?\n",
    "import numpy as np\n",
    "# Dataset 1\n",
    "data1 = np.array([1, 2, 3, 4, 5])\n",
    "std_dev1 = np.std(data1)\n",
    "\n",
    "# Dataset 2\n",
    "data2 = np.array([1, 1, 1, 10, 10])\n",
    "std_dev2 = np.std(data2)\n",
    "\n",
    "print(\"Standard Deviation of Dataset 1:\", std_dev1)\n",
    "print(\"Standard Deviation of Dataset 2:\", std_dev2)\n",
    "\n",
    "if std_dev1 < std_dev2:\n",
    "    print(\"Dataset 1 has less variability than Dataset 2\")\n",
    "else:\n",
    "    print(\"Dataset 2 has less variability than Dataset 1\")\n",
    "\n",
    "This code compares the standard deviations of two datasets, indicating which one has more variability or dispersion. A smaller standard deviation \n",
    "indicates less variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddccd4-22aa-4ccb-a74a-4c55be3421c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a Python program to visualize covariance using a heatmap?\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample dataset\n",
    "np.random.seed(0)\n",
    "data = np.random.multivariate_normal([0, 0, 0], [[1, 0.5, 0.7], [0.5, 1, 0.3], [0.7, 0.3, 1]], 100)\n",
    "\n",
    "# Calculate covariance matrix\n",
    "cov_matrix = np.cov(data.T)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cov_matrix, annot=True, cmap='coolwarm', square=True)\n",
    "plt.title('Covariance Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "This code generates a heatmap to visualize the covariance between variables in a multivariate dataset. The color intensity represents the strength\n",
    "of covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565f47a-c788-4ed3-b8ce-8d01d4501b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use seaborn to create a correlation matrix for a dataset?\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame(np.random.randn(100, 5), columns=['A', 'B', 'C', 'D', 'E'])\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "This code creates a correlation matrix heatmap using seaborn, displaying the correlation coefficients between variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c05bb4-7e78-48aa-a9e0-5ba84e0fca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generate a dataset and implement both variance and standard deviation computations?\n",
    "import numpy as np\n",
    "# Generate dataset\n",
    "np.random.seed(0)\n",
    "data = np.random.randn(10)\n",
    "\n",
    "# Calculate variance and standard deviation\n",
    "variance = np.var(data)\n",
    "std_dev = np.std(data)\n",
    "\n",
    "print(\"Dataset:\", data)\n",
    "print(\"Variance:\", variance)\n",
    "print(\"Standard Deviation:\", std_dev)\n",
    "\n",
    "This code generates a random dataset and calculates both variance (average of squared differences from the mean) and standard deviation\n",
    "(square root of variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4ce798-9431-48ce-8bbb-d7f2d8c4bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    " Visualize skewness and kurtosis using Python libraries like matplotlib or seaborn?\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Generate skewed and kurtotic data\n",
    "np.random.seed(0)\n",
    "skewed_data = stats.skewnorm.rvs(a=5, size=1000)\n",
    "kurtotic_data = stats.t.rvs(df=2, size=1000)\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(skewed_data, bins=30, alpha=0.7, color='blue')\n",
    "plt.title('Skewed Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(kurtotic_data, bins=30, alpha=0.7, color='red')\n",
    "plt.title('Kurtotic Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11e490-d6bb-4cfa-ae72-57b153d0eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implement the Pearson and Spearman correlation coefficients for a dataset?\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Sample dataset\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 3, 5, 7, 11])\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "pearson_coef, _ = pearsonr(x, y)\n",
    "\n",
    "# Calculate Spearman correlation\n",
    "spearman_coef, _ = spearmanr(x, y)\n",
    "\n",
    "print(\"Pearson Correlation:\", pearson_coef)\n",
    "print(\"Spearman Correlation:\", spearman_coef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
